{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ccc848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŸºç¡€ç¯å¢ƒæ£€æŸ¥ä¸åº“å®‰è£…\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# å®šä¹‰éœ€è¦å®‰è£…çš„åº“\n",
    "required_packages = [\"pymupdf\", \"pytesseract\", \"spacy\", \"pandas\", \"openpyxl\", \"requests\", \"pillow\"]\n",
    "\n",
    "# è‡ªåŠ¨å®‰è£…ç¼ºå¤±åº“ (è®©ä»£ç æ›´ç¨³å¥ï¼Œæ¢äº†ç”µè„‘ä¹Ÿèƒ½è·‘)\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        print(f\"æ­£åœ¨å®‰è£…ç¼ºå¤±åº“: {package}...\")\n",
    "        !{sys.executable} -m pip install {package} -q\n",
    "\n",
    "# ä¸‹è½½ spaCy æ¨¡å‹\n",
    "try:\n",
    "    import spacy\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"æ­£åœ¨ä¸‹è½½ spaCy è‹±æ–‡æ¨¡å‹...\")\n",
    "    !{sys.executable} -m spacy download en_core_web_sm\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "print(\"âœ… æ‰€æœ‰ç¯å¢ƒé…ç½®æ£€æŸ¥å®Œæ¯•ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309b1c39-0d42-4e1f-8e59-8458f34e7dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: æ ¸å¿ƒåŠŸèƒ½åº“å¯¼å…¥ (ä¿®å¤ç‰ˆ - å¢å¼ºä¸‹è½½åŠŸèƒ½)\n",
    "import fitz  # PyMuPDF\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import io\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# ã€é‡è¦é…ç½®ã€‘Windows ç”¨æˆ·è‹¥æŠ¥é”™ï¼Œè¯·å–æ¶ˆä¸‹é¢æ³¨é‡Šå¹¶ä¿®æ”¹è·¯å¾„\n",
    "pytesseract.pytesseract.tesseract_cmd = r'd:\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "def download_sample_pdf(url, filename=\"sample_paper.pdf\"):\n",
    "    \"\"\"\n",
    "    ç¨³å¥çš„ PDF ä¸‹è½½å‡½æ•°ï¼š\n",
    "    1. åŒ…å«æµè§ˆå™¨ä¼ªè£… (User-Agent)ã€‚\n",
    "    2. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ã€‚\n",
    "    3. æ£€æŸ¥æœåŠ¡å™¨è¿”å›çš„æ˜¯å¦çœŸçš„æ˜¯ PDF (Content-Type)ã€‚\n",
    "    \"\"\"\n",
    "    if os.path.exists(filename):\n",
    "        # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼Œå¦‚æœæ–‡ä»¶å¤ªå°ï¼ˆå°äº 10KBï¼‰ï¼Œå¯èƒ½æ˜¯ä¹‹å‰ä¸‹è½½åçš„ï¼Œå¼ºåˆ¶é‡æ–°ä¸‹è½½\n",
    "        file_size = os.path.getsize(filename)\n",
    "        if file_size > 10240: \n",
    "            print(f\"ğŸ“‚ æœ¬åœ°æ–‡ä»¶å·²å­˜åœ¨ä¸”æœ‰æ•ˆ ({file_size/1024:.1f} KB): {filename}\")\n",
    "            return filename\n",
    "        else:\n",
    "            print(f\"âš ï¸ å‘ç°æŸåçš„æ—§æ–‡ä»¶ ({file_size} bytes)ï¼Œæ­£åœ¨åˆ é™¤å¹¶é‡æ–°ä¸‹è½½...\")\n",
    "            os.remove(filename)\n",
    "    \n",
    "    print(f\"â¬‡ï¸ æ­£åœ¨ä¸‹è½½æµ‹è¯•æ–‡çŒ®: {url}...\")\n",
    "    \n",
    "    # === å…³é”®ä¿®å¤ 1: æ·»åŠ æµè§ˆå™¨ä¼ªè£…å¤´ (User-Agent) ===\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "        \"Referer\": \"https://www.google.com/\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # ä½¿ç”¨ headers å‘èµ·è¯·æ±‚\n",
    "        response = requests.get(url, headers=headers, stream=True, timeout=15)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # === å…³é”®ä¿®å¤ 2: æ£€æŸ¥å†…å®¹ç±»å‹ (Content-Type) ===\n",
    "        content_type = response.headers.get(\"Content-Type\", \"\").lower()\n",
    "        if \"pdf\" not in content_type and \"application/octet-stream\" not in content_type:\n",
    "            print(f\"âŒ ä¸‹è½½å¤±è´¥ï¼šæœåŠ¡å™¨è¿”å›çš„ä¸æ˜¯ PDFï¼Œè€Œæ˜¯ {content_type}\")\n",
    "            print(\"å¯èƒ½æ˜¯åçˆ¬è™«æ‹¦æˆªï¼Œå»ºè®®æ‰‹åŠ¨ä¸‹è½½ PDF å¹¶æ‹–å…¥æ–‡ä»¶å¤¹ã€‚\")\n",
    "            return None\n",
    "\n",
    "        # å†™å…¥æ–‡ä»¶\n",
    "        with open(filename, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        \n",
    "        print(f\"âœ… ä¸‹è½½å®Œæˆï¼æ–‡ä»¶å·²ä¿å­˜: {filename}\")\n",
    "        return filename\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ä¸‹è½½è¿‡ç¨‹å‡ºé”™: {e}\")\n",
    "        return None\n",
    "\n",
    "def smart_pdf_parser(pdf_path):\n",
    "    \"\"\"èƒ½å¤ŸåŒæ—¶å¤„ç†æ–‡æœ¬ç‰ˆå’Œæ‰«æç‰ˆ PDF çš„è§£æå™¨\"\"\"\n",
    "    if not pdf_path or not os.path.exists(pdf_path): \n",
    "        print(\"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ° PDF æ–‡ä»¶è·¯å¾„ã€‚\")\n",
    "        return \"\"\n",
    "    \n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "    except Exception as e:\n",
    "        # è¿™é‡Œèƒ½æ•æ‰åˆ°â€œæ–‡ä»¶æŸåâ€çš„é”™è¯¯\n",
    "        print(f\"âŒ æ— æ³•æ‰“å¼€ PDF æ–‡ä»¶ (æ–‡ä»¶å¯èƒ½å·²æŸå): {e}\")\n",
    "        print(\"ğŸ’¡ å»ºè®®ï¼šåˆ é™¤ç›®å½•ä¸‹çš„ .pdf æ–‡ä»¶ï¼Œé‡æ–°è¿è¡Œä¸‹è½½ä»£ç ï¼Œæˆ–æ‰‹åŠ¨ä¸Šä¼ ä¸€ä¸ªæ­£å¸¸çš„ PDFã€‚\")\n",
    "        return \"\"\n",
    "\n",
    "    full_text = []\n",
    "    print(f\"ğŸš€ å¼€å§‹å¤„ç†æ–‡ä»¶: {pdf_path} (å…± {len(doc)} é¡µ)...\")\n",
    "\n",
    "    for i, page in enumerate(doc):\n",
    "        # 1. å°è¯•ç›´æ¥æå–\n",
    "        text = page.get_text()\n",
    "        \n",
    "        # 2. æ‰«æä»¶æ£€æµ‹é€»è¾‘\n",
    "        if len(text.strip()) < 50:\n",
    "            print(f\"  âš ï¸ ç¬¬ {i+1} é¡µç–‘ä¼¼æ‰«æ/å›¾è¡¨ï¼Œå¯ç”¨ OCR è¯†åˆ«...\")\n",
    "            try:\n",
    "                pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))\n",
    "                img = Image.open(io.BytesIO(pix.tobytes(\"png\")))\n",
    "                text = pytesseract.image_to_string(img, lang='eng')\n",
    "            except Exception as e:\n",
    "                print(f\"  âŒ OCR å¤±è´¥ (ç¬¬ {i+1} é¡µ): {e}\")\n",
    "                # å¦‚æœ OCR å¤±è´¥ï¼Œä¿ç•™ç©ºæ–‡æœ¬ï¼Œé˜²æ­¢ç¨‹åºå´©æºƒ\n",
    "                text = \"\" \n",
    "        \n",
    "        full_text.append(text)\n",
    "    \n",
    "    return \"\\n\".join(full_text)\n",
    "\n",
    "# === è¿è¡Œå‡†å¤‡ ===\n",
    "# ä½¿ç”¨ Attention Is All You Need çš„å¤‡ç”¨é“¾æ¥ (Semantic Scholar é€šå¸¸æ¯” arXiv ç¨å¾®å®½æ¾ä¸€ç‚¹ï¼Œæˆ–è€…åšæŒç”¨ arXiv ä½†å¸¦ Header)\n",
    "# è¿™é‡Œçš„ URL ä¾ç„¶ç”¨ arXivï¼Œä½†é…åˆäº†æˆ‘ä»¬ä¸Šé¢çš„ headers ä¿®å¤\n",
    "pdf_url = \"https://arxiv.org/abs/2601.09348\"\n",
    "\n",
    "# è¿è¡Œä¸‹è½½\n",
    "local_pdf = download_sample_pdf(pdf_url, \"transformer_paper.pdf\")\n",
    "\n",
    "# å¦‚æœè‡ªåŠ¨ä¸‹è½½å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆæç¤º\n",
    "if local_pdf:\n",
    "    # æ‰§è¡Œè§£æ\n",
    "    raw_content = smart_pdf_parser(local_pdf)\n",
    "    if raw_content:\n",
    "        print(f\"âœ… è§£æå®Œæˆï¼Œå…±æå–å­—ç¬¦æ•°: {len(raw_content)}\")\n",
    "    else:\n",
    "        print(\"âŒ è§£æä¸­æ–­ï¼šæœªèƒ½æå–åˆ°å†…å®¹ã€‚\")\n",
    "else:\n",
    "    print(\"âŒ æ— æ³•è¿›è¡Œè§£æï¼Œå› ä¸º PDF ä¸‹è½½å¤±è´¥ã€‚\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca863ce8-b38e-4498-89af-826a7dc5464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ–‡æœ¬æ¸…æ´—ä¸æœ¯è¯­æŒ–æ˜ (Text Mining)\n",
    "def extract_terminology(text, top_k=50):\n",
    "    if not text: return pd.DataFrame()\n",
    "    \n",
    "    print(\"ğŸ§¹ æ­£åœ¨æ¸…æ´—æ–‡æœ¬å¹¶è¿›è¡Œ NLP åˆ†æ...\")\n",
    "    \n",
    "    # æ¸…æ´—ï¼šä¿®å¤æ–­è¯ (ex- ample -> example)\n",
    "    text = re.sub(r'(\\w+)-\\n(\\w+)', r'\\1\\2', text)\n",
    "    # æ¸…æ´—ï¼šåˆå¹¶æ¢è¡Œç¬¦\n",
    "    clean_text = text.replace('\\n', ' ')\n",
    "    \n",
    "    # NLP å¤„ç† (æˆªå–å‰ 50ä¸‡å­—ç¬¦é˜²æ­¢å†…å­˜æº¢å‡º)\n",
    "    doc = nlp(clean_text[:500000])\n",
    "    \n",
    "    candidates = []\n",
    "    sentences = list(doc.sents)\n",
    "    \n",
    "    # æå–åè¯çŸ­è¯­\n",
    "    for chunk in doc.noun_chunks:\n",
    "        term = chunk.text.lower().strip()\n",
    "        # ç­›é€‰è§„åˆ™ï¼šé•¿åº¦>2, å«ç©ºæ ¼, æ— æ•°å­—, éä»£è¯å¼€å¤´\n",
    "        if len(term) > 2 and \" \" in term and not any(c.isdigit() for c in term):\n",
    "             if chunk[0].pos_ != \"PRON\":\n",
    "                candidates.append(term)\n",
    "    \n",
    "    # ç»Ÿè®¡é¢‘ç‡\n",
    "    counts = Counter(candidates)\n",
    "    \n",
    "    # æ„å»ºæ•°æ®è¡¨ (å«ä¾‹å¥)\n",
    "    data = []\n",
    "    print(f\"ğŸ” æ­£åœ¨ä¸ºå‰ {top_k} ä¸ªæœ¯è¯­åŒ¹é…ä¾‹å¥...\")\n",
    "    \n",
    "    for term, freq in counts.most_common(top_k):\n",
    "        # æŸ¥æ‰¾ä¾‹å¥\n",
    "        context = \"Context not found\"\n",
    "        for sent in sentences:\n",
    "            if term in sent.text.lower():\n",
    "                context = sent.text.strip().replace('\\n', ' ')\n",
    "                break\n",
    "        \n",
    "        data.append({\n",
    "            \"Source Term\": term,\n",
    "            \"Frequency\": freq,\n",
    "            \"Context (Example)\": context,\n",
    "            \"Target Term (CN)\": \"\" # é¢„ç•™ç»™äººå·¥å¡«ç©º\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# æ‰§è¡Œæå–\n",
    "df_result = extract_terminology(raw_content)\n",
    "display(df_result.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64da0db-d573-4ac8-89f1-3681eabd39e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»“æœå¯¼å‡º\n",
    "output_file = \"Term_Glossary.xlsx\"\n",
    "try:\n",
    "    df_result.to_excel(output_file, index=False)\n",
    "    print(f\"ğŸ‰ æˆåŠŸï¼æ–‡ä»¶å·²ä¿å­˜è‡³: {os.path.abspath(output_file)}\")\n",
    "    print(\"ğŸ’¡ ä¸‹ä¸€æ­¥ï¼šåœ¨å·¦ä¾§æ–‡ä»¶æ å³é”®ç‚¹å‡»ä¸‹è½½ï¼Œæˆ–ç›´æ¥ä½¿ç”¨ Excel æ‰“å¼€ã€‚\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ä¿å­˜å¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb73352-a14b-4f46-85ff-0b46b9b62a12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d14a82f-cf2c-47d4-9652-587a7d99ae95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
