{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ccc848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨å®‰è£…ç¼ºå¤±åº“: pillow...\n",
      "âœ… æ‰€æœ‰ç¯å¢ƒé…ç½®æ£€æŸ¥å®Œæ¯•ï¼\n"
     ]
    }
   ],
   "source": [
    "# åŸºç¡€ç¯å¢ƒæ£€æŸ¥ä¸åº“å®‰è£…\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# å®šä¹‰éœ€è¦å®‰è£…çš„åº“\n",
    "required_packages = [\"pymupdf\", \"pytesseract\", \"spacy\", \"pandas\", \"openpyxl\", \"requests\", \"pillow\"]\n",
    "\n",
    "# è‡ªåŠ¨å®‰è£…ç¼ºå¤±åº“ (è®©ä»£ç æ›´ç¨³å¥ï¼Œæ¢äº†ç”µè„‘ä¹Ÿèƒ½è·‘)\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        print(f\"æ­£åœ¨å®‰è£…ç¼ºå¤±åº“: {package}...\")\n",
    "        !{sys.executable} -m pip install {package} -q\n",
    "\n",
    "# ä¸‹è½½ spaCy æ¨¡å‹\n",
    "try:\n",
    "    import spacy\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"æ­£åœ¨ä¸‹è½½ spaCy è‹±æ–‡æ¨¡å‹...\")\n",
    "    !{sys.executable} -m spacy download en_core_web_sm\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "print(\"âœ… æ‰€æœ‰ç¯å¢ƒé…ç½®æ£€æŸ¥å®Œæ¯•ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "309b1c39-0d42-4e1f-8e59-8458f34e7dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸ æ­£åœ¨ä¸‹è½½æµ‹è¯•æ–‡çŒ®: https://arxiv.org/abs/2601.09348...\n",
      "âœ… ä¸‹è½½å®Œæˆï¼\n",
      "ğŸš€ å¼€å§‹å¤„ç†æ–‡ä»¶ (å…± 11 é¡µ)...\n",
      "  âš ï¸ ç¬¬ 9 é¡µç–‘ä¼¼æ‰«æ/å›¾è¡¨ï¼Œå¯ç”¨ OCR è¯†åˆ«...\n",
      "  âŒ OCR å¤±è´¥ (ç¬¬ 9 é¡µ): d:\\Tesseract-OCR\\tesseract.exe is not installed or it's not in your PATH. See README file for more information. (è¯·ç¡®ä¿å·²å®‰è£… Tesseract è½¯ä»¶)\n",
      "  âš ï¸ ç¬¬ 11 é¡µç–‘ä¼¼æ‰«æ/å›¾è¡¨ï¼Œå¯ç”¨ OCR è¯†åˆ«...\n",
      "  âŒ OCR å¤±è´¥ (ç¬¬ 11 é¡µ): d:\\Tesseract-OCR\\tesseract.exe is not installed or it's not in your PATH. See README file for more information. (è¯·ç¡®ä¿å·²å®‰è£… Tesseract è½¯ä»¶)\n",
      "âœ… è§£æå®Œæˆï¼Œå…±æå–å­—ç¬¦æ•°: 4421\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: æ ¸å¿ƒåŠŸèƒ½åº“å¯¼å…¥\n",
    "import fitz  # PyMuPDF\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import io\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'd:\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "def download_sample_pdf(url, filename=\"sample_paper.pdf\"):\n",
    "    \"\"\"å¦‚æœæœ¬åœ°æ²¡æœ‰æ–‡ä»¶ï¼Œä»ç½‘ç»œä¸‹è½½ä¸€ä¸ªçœŸå®çš„å­¦æœ¯ PDF\"\"\"\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"ğŸ“‚ æœ¬åœ°æ–‡ä»¶å·²å­˜åœ¨: {filename}\")\n",
    "        return filename\n",
    "    \n",
    "    print(f\"â¬‡ï¸ æ­£åœ¨ä¸‹è½½æµ‹è¯•æ–‡çŒ®: {url}...\")\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(\"âœ… ä¸‹è½½å®Œæˆï¼\")\n",
    "        return filename\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ä¸‹è½½å¤±è´¥: {e}\")\n",
    "        return None\n",
    "\n",
    "def smart_pdf_parser(pdf_path):\n",
    "    \"\"\"èƒ½å¤ŸåŒæ—¶å¤„ç†æ–‡æœ¬ç‰ˆå’Œæ‰«æç‰ˆ PDF çš„è§£æå™¨\"\"\"\n",
    "    if not pdf_path: return \"\"\n",
    "    \n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æ— æ³•æ‰“å¼€ PDF: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "    full_text = []\n",
    "    print(f\"ğŸš€ å¼€å§‹å¤„ç†æ–‡ä»¶ (å…± {len(doc)} é¡µ)...\")\n",
    "\n",
    "    for i, page in enumerate(doc):\n",
    "        # 1. å°è¯•ç›´æ¥æå–\n",
    "        text = page.get_text()\n",
    "        \n",
    "        # 2. æ‰«æä»¶æ£€æµ‹é€»è¾‘ï¼šå¦‚æœä¸€é¡µå°‘äº 50 ä¸ªå­—ï¼Œåˆ¤å®šä¸ºå›¾ç‰‡\n",
    "        if len(text.strip()) < 50:\n",
    "            print(f\"  âš ï¸ ç¬¬ {i+1} é¡µç–‘ä¼¼æ‰«æ/å›¾è¡¨ï¼Œå¯ç”¨ OCR è¯†åˆ«...\")\n",
    "            try:\n",
    "                pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))\n",
    "                img = Image.open(io.BytesIO(pix.tobytes(\"png\")))\n",
    "                text = pytesseract.image_to_string(img, lang='eng')\n",
    "            except Exception as e:\n",
    "                print(f\"  âŒ OCR å¤±è´¥ (ç¬¬ {i+1} é¡µ): {e} (è¯·ç¡®ä¿å·²å®‰è£… Tesseract è½¯ä»¶)\")\n",
    "                text = \"\" # å¤±è´¥åˆ™è·³è¿‡è¯¥é¡µ\n",
    "        \n",
    "        full_text.append(text)\n",
    "    \n",
    "    return \"\\n\".join(full_text)\n",
    "\n",
    "# === è¿è¡Œå‡†å¤‡ ===\n",
    "# ä½¿ç”¨è‘—åçš„ \"Attention Is All You Need\" è®ºæ–‡ä½œä¸ºæµ‹è¯•\n",
    "# pdf_url = \"https://arxiv.org/pdf/1706.03762.pdf\"\n",
    "pdf_url = \"https://arxiv.org/abs/2601.09348\"\n",
    "local_pdf = download_sample_pdf(pdf_url, \"transformer_paper.pdf\")\n",
    "\n",
    "# æ‰§è¡Œè§£æ\n",
    "raw_content = smart_pdf_parser(local_pdf)\n",
    "print(f\"âœ… è§£æå®Œæˆï¼Œå…±æå–å­—ç¬¦æ•°: {len(raw_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca863ce8-b38e-4498-89af-826a7dc5464c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ æ­£åœ¨æ¸…æ´—æ–‡æœ¬å¹¶è¿›è¡Œ NLP åˆ†æ...\n",
      "ğŸ” æ­£åœ¨ä¸ºå‰ 50 ä¸ªæœ¯è¯­åŒ¹é…ä¾‹å¥...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source Term</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Context (Example)</th>\n",
       "      <th>Target Term (CN)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>giulia bevilacqua</td>\n",
       "      <td>4</td>\n",
       "      <td>Title:Existence and uniqueness of minimizers f...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>axisymmetric nematic films</td>\n",
       "      <td>3</td>\n",
       "      <td>Title:Existence and uniqueness of minimizers f...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a pdf</td>\n",
       "      <td>2</td>\n",
       "      <td>Title:Existence and uniqueness of minimizers f...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the paper</td>\n",
       "      <td>2</td>\n",
       "      <td>Title:Existence and uniqueness of minimizers f...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the nematic director</td>\n",
       "      <td>2</td>\n",
       "      <td>We study a variational model in which the nema...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Source Term  Frequency  \\\n",
       "0           giulia bevilacqua          4   \n",
       "1  axisymmetric nematic films          3   \n",
       "2                       a pdf          2   \n",
       "3                   the paper          2   \n",
       "4        the nematic director          2   \n",
       "\n",
       "                                   Context (Example) Target Term (CN)  \n",
       "0  Title:Existence and uniqueness of minimizers f...                   \n",
       "1  Title:Existence and uniqueness of minimizers f...                   \n",
       "2  Title:Existence and uniqueness of minimizers f...                   \n",
       "3  Title:Existence and uniqueness of minimizers f...                   \n",
       "4  We study a variational model in which the nema...                   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# æ–‡æœ¬æ¸…æ´—ä¸æœ¯è¯­æŒ–æ˜ (Text Mining)\n",
    "def extract_terminology(text, top_k=50):\n",
    "    if not text: return pd.DataFrame()\n",
    "    \n",
    "    print(\"ğŸ§¹ æ­£åœ¨æ¸…æ´—æ–‡æœ¬å¹¶è¿›è¡Œ NLP åˆ†æ...\")\n",
    "    \n",
    "    # æ¸…æ´—ï¼šä¿®å¤æ–­è¯ (ex- ample -> example)\n",
    "    text = re.sub(r'(\\w+)-\\n(\\w+)', r'\\1\\2', text)\n",
    "    # æ¸…æ´—ï¼šåˆå¹¶æ¢è¡Œç¬¦\n",
    "    clean_text = text.replace('\\n', ' ')\n",
    "    \n",
    "    # NLP å¤„ç† (æˆªå–å‰ 50ä¸‡å­—ç¬¦é˜²æ­¢å†…å­˜æº¢å‡º)\n",
    "    doc = nlp(clean_text[:500000])\n",
    "    \n",
    "    candidates = []\n",
    "    sentences = list(doc.sents)\n",
    "    \n",
    "    # æå–åè¯çŸ­è¯­\n",
    "    for chunk in doc.noun_chunks:\n",
    "        term = chunk.text.lower().strip()\n",
    "        # ç­›é€‰è§„åˆ™ï¼šé•¿åº¦>2, å«ç©ºæ ¼, æ— æ•°å­—, éä»£è¯å¼€å¤´\n",
    "        if len(term) > 2 and \" \" in term and not any(c.isdigit() for c in term):\n",
    "             if chunk[0].pos_ != \"PRON\":\n",
    "                candidates.append(term)\n",
    "    \n",
    "    # ç»Ÿè®¡é¢‘ç‡\n",
    "    counts = Counter(candidates)\n",
    "    \n",
    "    # æ„å»ºæ•°æ®è¡¨ (å«ä¾‹å¥)\n",
    "    data = []\n",
    "    print(f\"ğŸ” æ­£åœ¨ä¸ºå‰ {top_k} ä¸ªæœ¯è¯­åŒ¹é…ä¾‹å¥...\")\n",
    "    \n",
    "    for term, freq in counts.most_common(top_k):\n",
    "        # æŸ¥æ‰¾ä¾‹å¥\n",
    "        context = \"Context not found\"\n",
    "        for sent in sentences:\n",
    "            if term in sent.text.lower():\n",
    "                context = sent.text.strip().replace('\\n', ' ')\n",
    "                break\n",
    "        \n",
    "        data.append({\n",
    "            \"Source Term\": term,\n",
    "            \"Frequency\": freq,\n",
    "            \"Context (Example)\": context,\n",
    "            \"Target Term (CN)\": \"\" # é¢„ç•™ç»™äººå·¥å¡«ç©º\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# æ‰§è¡Œæå–\n",
    "df_result = extract_terminology(raw_content)\n",
    "display(df_result.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c64da0db-d573-4ac8-89f1-3681eabd39e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ æˆåŠŸï¼æ–‡ä»¶å·²ä¿å­˜è‡³: D:\\20260118-Python-nlp\\Term_Glossary.xlsx\n",
      "ğŸ’¡ ä¸‹ä¸€æ­¥ï¼šåœ¨å·¦ä¾§æ–‡ä»¶æ å³é”®ç‚¹å‡»ä¸‹è½½ï¼Œæˆ–ç›´æ¥ä½¿ç”¨ Excel æ‰“å¼€ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ç»“æœå¯¼å‡º\n",
    "output_file = \"Term_Glossary.xlsx\"\n",
    "try:\n",
    "    df_result.to_excel(output_file, index=False)\n",
    "    print(f\"ğŸ‰ æˆåŠŸï¼æ–‡ä»¶å·²ä¿å­˜è‡³: {os.path.abspath(output_file)}\")\n",
    "    print(\"ğŸ’¡ ä¸‹ä¸€æ­¥ï¼šåœ¨å·¦ä¾§æ–‡ä»¶æ å³é”®ç‚¹å‡»ä¸‹è½½ï¼Œæˆ–ç›´æ¥ä½¿ç”¨ Excel æ‰“å¼€ã€‚\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ä¿å­˜å¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb73352-a14b-4f46-85ff-0b46b9b62a12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d14a82f-cf2c-47d4-9652-587a7d99ae95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
