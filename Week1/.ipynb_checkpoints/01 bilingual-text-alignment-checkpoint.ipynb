{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b52c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1\n",
    "# uv pip install pandas openpyxl python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3659406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Auto-Detection Successful!\n",
      "ğŸ“‚ Found 2 file(s). We will process: 'CGTN-bilingual-news - å‰¯æœ¬.txt'\n",
      "   (Other files ignored: ['CGTN-bilingual-news.txt'])\n",
      "\n",
      "--- ğŸ“„ File Content Preview (First 500 chars) ---\n",
      "2024å¹´ä¸­éåˆä½œè®ºå›å³°ä¼šå°†äº9æœˆ4æ—¥è‡³6æ—¥åœ¨åŒ—äº¬ä¸¾è¡Œã€‚éæ´²å„ç•Œäººå£«è¡¨ç¤ºï¼Œä¸­éåˆä½œå·²å–å¾—ä¸°ç¡•æˆæœï¼Œå³å°†å¬å¼€çš„ä¸­éåˆä½œè®ºå›å³°ä¼šå°†æˆä¸ºæ·±åŒ–ä¸­éåˆä½œçš„é‡è¦å¥‘æœºï¼ŒæœŸå¾…åŒæ–¹ä¸æ–­æ‹“å±•åˆä½œæ–°é¢†åŸŸï¼Œå…±è°‹å‘å±•æ–°ç¯‡ç« ã€‚\n",
      "\n",
      "\n",
      "The upcoming 2024 Summit of the Forum on China-Africa Cooperation is expected to bear fruitful results to further deepen Sino-African relations, according to observers in Africa.\n",
      "éæ´²è§‚å¯Ÿäººå£«ç§°ï¼Œå³å°†å¬å¼€çš„2024å¹´ä¸­éåˆä½œè®ºå›å³°ä¼šæœ‰æœ›å–å¾—ä¸°ç¡•æˆæœï¼Œè¿›ä¸€æ­¥æ·±åŒ–ä¸­éå…³ç³»ã€‚\n",
      "\n",
      "Alan Khan, senior director of corporate affairs at Durban University of Technology in Durban, South Africa, said the summit, to be held from Sept 4 to 6 in Beijing, is expe\n",
      "...\n",
      "(End of preview)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def find_and_preview_file():\n",
    "    \"\"\"\n",
    "    Scans the current directory for .txt files containing 'bilingual'.\n",
    "    Returns the filename if found, otherwise creates a demo file.\n",
    "    \"\"\"\n",
    "    # 1. Define the search pattern\n",
    "    # The asterisk (*) is a wildcard. \"*bilingual*.txt\" means:\n",
    "    # \"Any characters\" + \"bilingual\" + \"Any characters\" + \".txt\"\n",
    "    search_pattern = \"*bilingual*.txt\"\n",
    "    \n",
    "    # 2. Use glob to find all matching files in the folder\n",
    "    found_files = glob.glob(search_pattern)\n",
    "    \n",
    "    target_filename = \"\"\n",
    "\n",
    "    # 3. Decision Logic\n",
    "    if len(found_files) > 0:\n",
    "        # If we found files, we pick the first one automatically\n",
    "        target_filename = found_files[0]\n",
    "        print(f\"âœ… Auto-Detection Successful!\")\n",
    "        print(f\"ğŸ“‚ Found {len(found_files)} file(s). We will process: '{target_filename}'\")\n",
    "        \n",
    "        # If there are multiple files, list them for user awareness\n",
    "        if len(found_files) > 1:\n",
    "            print(f\"   (Other files ignored: {found_files[1:]})\")\n",
    "            \n",
    "    else:\n",
    "        # If NO file is found, we create a dummy one so the code doesn't crash\n",
    "        print(\"âŒ No text file containing 'bilingual' was found.\")\n",
    "        print(\"âš ï¸ Creating a 'demo_bilingual_test.txt' for demonstration purposes...\")\n",
    "        \n",
    "        target_filename = \"demo_bilingual_test.txt\"\n",
    "        dummy_content = \"\"\"\n",
    "        Contract Agreement for Service\n",
    "        æœåŠ¡åˆåŒåè®®ä¹¦\n",
    "        \n",
    "        This Agreement is made on January 23, 2026.\n",
    "        æœ¬åè®®äº 2026 å¹´ 1 æœˆ 23 æ—¥ ç­¾è®¢ã€‚\n",
    "        \n",
    "        Party A: Tech Solutions Inc. (The \"Client\")\n",
    "        ç”²æ–¹ï¼šTech Solutions Inc.ï¼ˆä»¥ä¸‹ç®€ç§°â€œå®¢æˆ·â€ï¼‰\n",
    "        \n",
    "        Party B: Global Services Ltd. (The \"Provider\")\n",
    "        ä¹™æ–¹ï¼šå…¨çƒæœåŠ¡æœ‰é™å…¬å¸ï¼ˆä»¥ä¸‹ç®€ç§°â€œæä¾›å•†â€ï¼‰\n",
    "        \"\"\"\n",
    "        with open(target_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(dummy_content)\n",
    "        print(f\"âœ… Demo file created: {target_filename}\")\n",
    "\n",
    "    # 4. Read and Preview the content (Safety Check)\n",
    "    # This ensures the file is readable and shows you the first few lines\n",
    "    try:\n",
    "        with open(target_filename, 'r', encoding='utf-8') as f:\n",
    "            preview = f.read(500) # Read only first 500 characters\n",
    "        \n",
    "        print(\"\\n--- ğŸ“„ File Content Preview (First 500 chars) ---\")\n",
    "        print(preview)\n",
    "        print(\"...\\n(End of preview)\")\n",
    "        \n",
    "    except UnicodeDecodeError:\n",
    "        print(\"âŒ Error: The file encoding is not UTF-8. Please save your txt file as UTF-8.\")\n",
    "    \n",
    "    return target_filename\n",
    "\n",
    "# Execute the function and store the filename in a variable\n",
    "# We will use 'current_processing_file' in Cell 3\n",
    "current_processing_file = find_and_preview_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c5b1633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 84 English lines and 84 Chinese lines.\n",
      "Excel file created: aligned_20260123_133826.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source (English)</th>\n",
       "      <th>Target (Chinese)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The upcoming 2024 Summit of the Forum on China...</td>\n",
       "      <td>éæ´²è§‚å¯Ÿäººå£«ç§°ï¼Œå³å°†å¬å¼€çš„2024å¹´ä¸­éåˆä½œè®ºå›å³°ä¼šæœ‰æœ›å–å¾—ä¸°ç¡•æˆæœï¼Œè¿›ä¸€æ­¥æ·±åŒ–ä¸­éå…³ç³»ã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alan Khan, senior director of corporate affair...</td>\n",
       "      <td>å—éå¾·ç­ç†å·¥å¤§å­¦ä¼ä¸šäº‹åŠ¡é«˜çº§ä¸»ä»»è‰¾ä¼¦Â·æ±—è¡¨ç¤ºï¼Œæ­¤æ¬¡å³°ä¼šå°†äº9æœˆ4æ—¥è‡³6æ—¥åœ¨åŒ—äº¬ä¸¾è¡Œï¼Œé¢„è®¡å°†å·©...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"FOCAC has been highly beneficial in nurturing...</td>\n",
       "      <td>è‰¾ä¼¦Â·æ±—è¡¨ç¤ºï¼Œâ€œä¸­éåˆä½œè®ºå›å¯¹ä¸­éå…³ç³»å¤§æœ‰è£¨ç›Šã€‚åœ¨ä¸­éåˆä½œè®ºå›æ¡†æ¶ä¸‹ï¼Œä¸­å›½å¯¹éæ´²çš„å…¬è·¯ã€é“è·¯...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dianah Ngui Muchai, a research manager at Keny...</td>\n",
       "      <td>è‚¯å°¼äºšéæ”¿åºœç»„ç»‡éæ´²ç»æµç ”ç©¶ä¼šç ”ç©¶ç»ç†é»›å®‰å¨œÂ·æ©å‰Â·ç©†æŸ¥è¡¨ç¤ºï¼Œä¸­å›½æ˜¯è®¸å¤šéæ´²å›½å®¶çš„é‡è¦åˆä½œä¼™...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Looking forward, Muchai said more bilateral co...</td>\n",
       "      <td>å±•æœ›æœªæ¥ï¼Œç©†æŸ¥è¡¨ç¤ºï¼Œéšç€éæ´²å¯»æ±‚æ»¡è¶³æ—¥ç›Šå¢é•¿çš„èƒ½æºéœ€æ±‚å¹¶å‘å¯æŒç»­èƒ½æºè¿ˆè¿›ï¼Œä¸­éåˆä½œè®ºå›æœ‰æœ›æ¨...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Source (English)  \\\n",
       "0  The upcoming 2024 Summit of the Forum on China...   \n",
       "1  Alan Khan, senior director of corporate affair...   \n",
       "2  \"FOCAC has been highly beneficial in nurturing...   \n",
       "3  Dianah Ngui Muchai, a research manager at Keny...   \n",
       "4  Looking forward, Muchai said more bilateral co...   \n",
       "\n",
       "                                    Target (Chinese)  \n",
       "0      éæ´²è§‚å¯Ÿäººå£«ç§°ï¼Œå³å°†å¬å¼€çš„2024å¹´ä¸­éåˆä½œè®ºå›å³°ä¼šæœ‰æœ›å–å¾—ä¸°ç¡•æˆæœï¼Œè¿›ä¸€æ­¥æ·±åŒ–ä¸­éå…³ç³»ã€‚  \n",
       "1  å—éå¾·ç­ç†å·¥å¤§å­¦ä¼ä¸šäº‹åŠ¡é«˜çº§ä¸»ä»»è‰¾ä¼¦Â·æ±—è¡¨ç¤ºï¼Œæ­¤æ¬¡å³°ä¼šå°†äº9æœˆ4æ—¥è‡³6æ—¥åœ¨åŒ—äº¬ä¸¾è¡Œï¼Œé¢„è®¡å°†å·©...  \n",
       "2  è‰¾ä¼¦Â·æ±—è¡¨ç¤ºï¼Œâ€œä¸­éåˆä½œè®ºå›å¯¹ä¸­éå…³ç³»å¤§æœ‰è£¨ç›Šã€‚åœ¨ä¸­éåˆä½œè®ºå›æ¡†æ¶ä¸‹ï¼Œä¸­å›½å¯¹éæ´²çš„å…¬è·¯ã€é“è·¯...  \n",
       "3  è‚¯å°¼äºšéæ”¿åºœç»„ç»‡éæ´²ç»æµç ”ç©¶ä¼šç ”ç©¶ç»ç†é»›å®‰å¨œÂ·æ©å‰Â·ç©†æŸ¥è¡¨ç¤ºï¼Œä¸­å›½æ˜¯è®¸å¤šéæ´²å›½å®¶çš„é‡è¦åˆä½œä¼™...  \n",
       "4  å±•æœ›æœªæ¥ï¼Œç©†æŸ¥è¡¨ç¤ºï¼Œéšç€éæ´²å¯»æ±‚æ»¡è¶³æ—¥ç›Šå¢é•¿çš„èƒ½æºéœ€æ±‚å¹¶å‘å¯æŒç»­èƒ½æºè¿ˆè¿›ï¼Œä¸­éåˆä½œè®ºå›æœ‰æœ›æ¨...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime  # æ–°å¢ï¼šç”¨äºè·å–å½“å‰æ—¶é—´\n",
    "def is_contains_chinese(string):\n",
    "    \"\"\"\n",
    "    Check if the string contains any Chinese characters.\n",
    "    \"\"\"\n",
    "    for char in string:\n",
    "        if '\\u4e00' <= char <= '\\u9fff':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def process_text_smartly(input_file, output_excel):\n",
    "    # 1. Read lines and remove completely empty lines immediately\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        # strict filtering: remove whitespace and check if anything remains\n",
    "        raw_lines = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "    source_lines = [] # English\n",
    "    target_lines = [] # Chinese\n",
    "\n",
    "    # 2. Classify each line based on content, not position\n",
    "    for line in raw_lines:\n",
    "        if is_contains_chinese(line):\n",
    "            target_lines.append(line)\n",
    "        else:\n",
    "            source_lines.append(line)\n",
    "\n",
    "    # 3. Validation\n",
    "    # We ensure both lists have the same length for the table\n",
    "    len_source = len(source_lines)\n",
    "    len_target = len(target_lines)\n",
    "    \n",
    "    print(f\"Found {len_source} English lines and {len_target} Chinese lines.\")\n",
    "    \n",
    "    # Handle mismatches by truncating to the shorter length to prevent errors\n",
    "    min_len = min(len_source, len_target)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'Source (English)': source_lines[:min_len],\n",
    "        'Target (Chinese)': target_lines[:min_len]\n",
    "    })\n",
    "\n",
    "    df.to_excel(output_excel, index=False)\n",
    "    print(f\"Excel file created: {output_excel}\")\n",
    "    return df\n",
    "\n",
    "# 1. è·å–å½“å‰æ—¶é—´å¹¶æ ¼å¼åŒ–ï¼ˆæ ¼å¼ï¼šå¹´æœˆæ—¥_æ—¶åˆ†ç§’ï¼Œæ— ç‰¹æ®Šå­—ç¬¦ï¼Œå…¼å®¹å…¨ç³»ç»Ÿï¼‰\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# 2. æ‹¼æ¥æ—¶é—´æˆ³åˆ°æ–‡ä»¶åä¸­ï¼Œä¿æŒ.xlsxæ‰©å±•å\n",
    "output_filename = f\"aligned_{current_time}.xlsx\"\n",
    "\n",
    "# Run the function\n",
    "df_result = process_text_smartly(\"CGTN-bilingual-news.txt\", output_filename)\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87c59be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word document saved as: Layout_20260123_133826.docx\n"
     ]
    }
   ],
   "source": [
    "# Cell 4\n",
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "from docx.oxml.ns import qn\n",
    "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
    "\n",
    "def create_formatted_word(dataframe, output_filename):\n",
    "    doc = Document()\n",
    "    \n",
    "    # Title\n",
    "    heading = doc.add_heading('Bilingual Translation Table', 0)\n",
    "    heading.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "\n",
    "    # Create Table\n",
    "    table = doc.add_table(rows=len(dataframe) + 1, cols=2)\n",
    "    table.style = 'Table Grid'\n",
    "\n",
    "    # Header\n",
    "    hdr_cells = table.rows[0].cells\n",
    "    hdr_cells[0].text = 'Source Text'\n",
    "    hdr_cells[1].text = 'Target Text'\n",
    "\n",
    "    # Fill Data\n",
    "    for i in range(len(dataframe)):\n",
    "        # Get text from dataframe\n",
    "        en_text = dataframe.iloc[i]['Source (English)']\n",
    "        zh_text = dataframe.iloc[i]['Target (Chinese)']\n",
    "        \n",
    "        # Get table cells\n",
    "        row_cells = table.rows[i+1].cells\n",
    "        \n",
    "        # Format English Column (Left)\n",
    "        p_en = row_cells[0].paragraphs[0]\n",
    "        run_en = p_en.add_run(en_text)\n",
    "        run_en.font.name = 'Times New Roman'\n",
    "        run_en.font.size = Pt(11)\n",
    "        \n",
    "        # Format Chinese Column (Right)\n",
    "        p_zh = row_cells[1].paragraphs[0]\n",
    "        run_zh = p_zh.add_run(zh_text)\n",
    "        run_zh.font.name = 'SimSun' # Set to Songti\n",
    "        run_zh.font.size = Pt(11)\n",
    "        # XML fix for Chinese font rendering\n",
    "        run_zh._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')\n",
    "\n",
    "    doc.save(output_filename)\n",
    "    print(f\"Word document saved as: {output_filename}\")\n",
    "output_docx_filename = f\"Layout_{current_time}.docx\"\n",
    "# Run the function\n",
    "create_formatted_word(df_result, output_docx_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1262a783-cf72-4586-a79e-d314a205bab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f6c5d1-bdff-45fa-8041-c6e1ac57d7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
