1
00:00:03,300 --> 00:00:13,250
大家好，欢迎来到本次分享！我会讲解如何用Python自然语言处理技术，实现翻译场景的办公自动化

2
00:00:13,620 --> 00:00:19,820
我已经仔细看完大家提交的问卷，结合大家的背景和需求，定制了本次分享的内容

3
00:00:19,820 --> 00:00:25,210
大家请认真听，今天的内容会直接解决大家提出的痛点问题

4
00:00:25,830 --> 00:00:35,780
我注意到大家大多是硕士研究生，目前科研压力不小，也都很关注语料库处理和学术写作的相关问题

5
00:00:36,480 --> 00:00:41,630
很多人可能会疑惑，现在AI工具这么强大，为什么还要学Python？

6
00:00:42,270 --> 00:00:51,520
大家在反馈里其实也提到，AI经常会产生幻觉、编造术语，根本不敢直接用

7
00:00:52,350 --> 00:00:59,460
此外，AI有输入输出字符限制，没法一次性处理上千份文档或整个文件夹的内容

8
00:01:00,040 --> 00:01:08,820
而Python的作用就在这里：它能打通AI和本地文件，突破网页端限制，处理海量数据

9
00:01:09,580 --> 00:01:13,700
从数据来看，大家几乎都在用Windows 10或Windows 11系统

10
00:01:13,710 --> 00:01:20,990
有少数同学用Mac，我会主要讲Windows的配置方法，同时标注出Mac用户的操作差异

11
00:01:21,800 --> 00:01:27,520
关于大家的技术基础，约一半同学对绝对文件路径这类概念不太清楚

12
00:01:28,120 --> 00:01:37,860
大家不用担扰，我们不会讲复杂的计算机概念，只教实用方法，无论文件存在哪都能用上

13
00:01:38,450 --> 00:01:43,660
问卷也梳理出了大家做翻译最头疼的问题，今天我们就一一解决

14
00:01:44,440 --> 00:01:52,900
大家最头疼的就是处理 word 文档转换的 PDF：里面有大量多余的换行和杂乱的页眉页脚，都得手动删除

15
00:01:53,420 --> 00:01:55,820
我们会写一个脚本，一键解决这个问题

16
00:01:56,520 --> 00:02:06,100
第二个大问题，是手动对齐中英文文本制作TMX翻译记忆库，全程复制粘贴特别繁琐

17
00:02:06,480 --> 00:02:11,560
我们会看看Python如何自动化这些重复操作，为大家节省数小时的工作量

18
00:02:12,250 --> 00:02:15,980
我还想说说大家对写代码的顾虑

19
00:02:16,320 --> 00:02:22,730
很多同学说，看到红色的报错提示，第一反应就是关掉软件或等别人帮忙

20
00:02:23,120 --> 00:02:33,880
我跟大家保证，今天的目标不是让大家背 Python 语法，而是教大家写提示词让AI写代码，更重要的是，让AI帮大家解决这些报错

21
00:02:34,460 --> 00:02:40,650
对于只想用一键工具、不想学原理的同学，我们也会提供打包好的脚本

22
00:02:40,650 --> 00:02:43,940
但我还是建议大家理解背后的逻辑，这样才能自己修改定制

23
00:02:44,750 --> 00:02:47,260
现在我们来看环境配置

24
00:02:48,000 --> 00:02:52,500
大家大多用Windows，首先要确保大家有运行脚本的权限

25
00:02:53,060 --> 00:02:58,510
好在大部分同学都有 Windows 的管理员权限

26
00:02:58,510 --> 00:03:07,490
大家需要以管理员身份打开 PowerShell，将执行策略改为远程签名，这样就能运行我们的自动化脚本了

27
00:03:07,500 --> 00:03:16,490
Mac用户激活环境要用到另外的命令，更多注意事项，我也写在课程PDF里了

28
00:03:16,490 --> 00:03:20,890
有同学说，访问国外网站速度很慢，甚至根本打不开

29
00:03:21,480 --> 00:03:27,010
为了解决这个问题，我们会用优化的镜像源，加快Python库的下载速度

30
00:03:27,010 --> 00:03:29,240
所以大家完全不用担扰网速的问题

31
00:03:30,100 --> 00:03:40,450
我们会安装大家感兴趣的库：数据处理用的pandas、文本分析用的NLTK，还会为想做办公流程自动化（RPA) 的同学装相关工具

32
00:03:41,460 --> 00:03:48,920
最后说下学习资料，很多同学想要视频回放和PDF教程，方便自己按节奏复习

33
00:03:49,460 --> 00:03:58,890
这些资料我们都准备好了，还有从零开始的环境配置指南，大家现在专心听，之后在实际工作中练习就行

34
00:03:58,890 --> 00:04:03,540
企业级开发和个人效率开发，有着本质的区别

35
00:04:04,000 --> 00:04:10,980
企业级开发重架构、重安全、重高并发处理，这是专业程序员的工作

36
00:04:11,250 --> 00:04:14,680
而个人效率开发，核心是高效、轻量化

37
00:04:14,680 --> 00:04:23,080
所以我们的学习目标，不是写完美的软件，而是用几十行代码解决机械重复的操作，省下大量时间

38
00:04:23,480 --> 00:04:35,330
各类AI工具和传统办公软件都是孤立的，而Python的核心价值，就是做连接它们的胶水，把AI、Word、PDF、数据库粘连起来，打造专属的工作流

39
00:04:36,130 --> 00:04:41,430
这正好能解决翻译工作的两个痛点：数据清洗和格式排版

40
00:04:42,240 --> 00:04:47,410
接下来，我会分享Python在翻译办公自动化中的两个核心应用案例

41
00:04:47,800 --> 00:05:00,080
【第一个案例：制作双语对照表】翻译工作中常遇到长文档，原文和译文上下排列，我们需要把它们做成双语对照的表格

42
00:05:00,540 --> 00:05:06,900
手动复制粘贴效率极低，而AI处理又有文本输入量的限制

43
00:05:07,110 --> 00:05:22,860
而Python可以无限制读取文本，区分原文和译文行，借助pandas库一键导出Excel，还能直接生成字体、行距都调好的Word文档，不用手动调整

44
00:05:23,370 --> 00:05:28,070
大家可以把这个程序理解成一个智能助手，帮大家整理翻译工作

45
00:05:28,500 --> 00:05:34,620
它的作用，就是把中英文句子混杂的文本文件，转换成规范的对照表

46
00:05:34,960 --> 00:05:37,020
这个流程从配置阶段开始

47
00:05:37,720 --> 00:05:41,990
代码会先加载读写文档所需的各类工具

48
00:05:42,550 --> 00:05:48,650
工具准备好后，程序会像侦探一样，扫描你当前的工作文件夹

49
00:05:49,320 --> 00:05:53,910
它会专门查找文件名里指定的双语对照文本文件

50
00:05:54,220 --> 00:05:57,330
如果找到，就会立刻开始处理这个文件

51
00:05:58,040 --> 00:06:06,140
如果没找到，它也不会崩溃或停止运行，而是会自动为大家生成一个示例文件

52
00:06:06,330 --> 00:06:09,530
这样就能保证整个流程始终能正常执行

53
00:06:09,800 --> 00:06:12,660
文件准备就绪后，处理环节就开始了

54
00:06:13,390 --> 00:06:15,580
大家可以把这一步理解成一个分类机

55
00:06:16,140 --> 00:06:19,570
程序会从上到下，逐行读取文本文件的内容

56
00:06:19,830 --> 00:06:29,860
它会跳过空行，保证内容整洁，然后对每一行做判断：这一行里有中文字符吗？

57
00:06:30,160 --> 00:06:34,140
如果有，就把这一行归到中文组

58
00:06:34,920 --> 00:06:38,530
如果没有，就把这一行归到英文组

59
00:06:38,780 --> 00:06:55,150
所有句子分类完成后，程序会把它们一一对应并排，生成Excel 表格：第一列是英文，第二列是中文，为了方便整理，它还会获取当前的准确时间

60
00:06:55,650 --> 00:06:59,940
它会把时间加到文件名里，这样大家就不会不小心覆盖之前的文件了

61
00:07:01,340 --> 00:07:03,680
随后这个Excel表格就会保存到大家的电脑里

62
00:07:04,120 --> 00:07:14,980
最后一步，为了让结果阅读起来更美观，程序会打开一个空白Word文档，制作一个和Excel表格一样的双语对照表格

63
00:07:15,640 --> 00:07:18,160
并把分类好的文本填充到表格里

64
00:07:18,350 --> 00:07:29,680
它还会像帮你把 Word 排版好，把英文改成标准字体【新时代牛马】，中文也设置成适合的字体，让显示效果更好

65
00:07:30,260 --> 00:07:43,120
最终会保存好这份排版精美的文档：从一个简单的文本文件，到格式完美的 Excel 和 Word，全程不费吹灰之力！

66
00:07:43,770 --> 00:07:48,870
第二个案例：批量处理无法直接复制的扫描版PDF

67
00:07:48,970 --> 00:07:58,840
Python可以遍历存放PDF的文件夹，调用百度智能云、阿里云等AI接口，完成文本识别

68
00:07:59,440 --> 00:08:03,740
我们还能用到多线程技术，提高识别的速度

69
00:08:04,430 --> 00:08:16,000
注意：有些AI接口有每秒查询次数的限制，大家可以选限制宽松的接口，也可以在代码里加延迟，避免因请求过快被服务器屏蔽

70
00:08:17,140 --> 00:08:29,450
如果处理合同这类机密文件，大家可以把免费的开源离线模型下载到本地，用Python库处理，不用上传到云端，保证数据安全

71
00:08:30,220 --> 00:08:34,040
这个项目就像一个高智能的研究助手

72
00:08:34,770 --> 00:08:42,780
它的主要工作，是读取复杂的学术PDF，自动提取里面最核心的技术术语和概念

73
00:08:43,620 --> 00:08:49,910
试想一下，面对一篇信息高度密集的学术论文，你想做一份专业术语词汇表，却不想逐句阅读（这可能吗？）

74
00:08:50,370 --> 00:08:56,180
其实程序就能做到，它会用到一系列高级筛选规则和评分体系

75
00:08:56,590 --> 00:08:58,980
这个流程从准备阶段开始

76
00:08:59,470 --> 00:09:05,420
电脑会先加载理解人类文本所需的所有工具和词典

77
00:09:05,800 --> 00:09:10,170
工具加载完成后，程序会导入你要分析的PDF文档

78
00:09:10,700 --> 00:09:12,370
它就像一个极其细心的读者

79
00:09:12,780 --> 00:09:15,920
打开文件后，它会先修正常见的格式错误

80
00:09:16,430 --> 00:09:21,750
比如，单词在行尾被连字符拆分，它会把单词重新拼接完整

81
00:09:22,120 --> 00:09:27,840
它还会删掉参考文献编号这类干扰标记，专注于文本本身

82
00:09:28,430 --> 00:09:33,540
文本清理完成后，程序就进入最关键的步骤：寻找潜在的专业术语

83
00:09:34,110 --> 00:09:37,880
它会依据一系列语言规则，寻找特定的文本模式

84
00:09:38,200 --> 00:09:43,080
它会专门筛选名词短语，专业术语基本都藏在这类短语里

85
00:09:43,540 --> 00:09:48,380
比如人工智能、神经网络这类组合，都会被筛选出来

86
00:09:48,680 --> 00:09:52,430
同时，它就像一个带着黑名单的保安

87
00:09:53,110 --> 00:10:03,810
会自动屏蔽通用的学术套话，比如图、表、结论、因此这类词，这些都不是有价值的专业术语

88
00:10:04,700 --> 00:10:10,170
它会过滤掉成千上万个无用词汇，只留下高质量的术语

89
00:10:10,910 --> 00:10:14,540
得到潜在术语列表后，程序就会扮演裁判的角色

90
00:10:14,900 --> 00:10:19,200
它会通过评分体系，判断每个术语的重要程度

91
00:10:19,540 --> 00:10:25,080
它会统计术语的出现频率，还会判断这个术语在这份文档里的独特性

92
00:10:25,610 --> 00:10:35,520
这样能避免常用词获得高分，还会做智能合并，比如把method和methods这类相近的术语合并成一个

93
00:10:36,060 --> 00:10:41,360
如果短术语是更长的优质术语的一部分，它会删掉短的，避免重复

94
00:10:42,560 --> 00:10:49,880
最后，程序会整理所有通过筛选的术语，按照重要性得分进行排序

95
00:10:50,500 --> 00:10:55,650
它还会抓取术语在原文中的使用片段，方便大家查看上下文

96
00:10:55,850 --> 00:10:59,400
并把所有信息保存到一份整洁的Excel表格里

97
00:10:59,730 --> 00:11:08,360
大家最终会得到一份简洁专业的词汇表，里面有英文术语、预留的翻译列，还有术语的文档重要性评分

98
00:11:09,370 --> 00:11:14,740
我还想说明，为什么我们还要学习传统的自然语言处理方法

99
00:11:14,750 --> 00:11:17,150
即便现在的AI能力已经很强

100
00:11:17,810 --> 00:11:26,580
AI还是会产生幻觉，输出结果也难以完全控制，而传统方法在数据提取和专业文本分析上，精度会更高

101
00:11:27,230 --> 00:11:37,790
通过光学字符识别获取文本后，我们可以用传统方法完成分词、去停用词、词性标注等一系列处理

102
00:11:38,520 --> 00:11:45,200
还能自动提取实体信息，比如人名、地名、机构名、时间、金额等

103
00:11:45,830 --> 00:11:57,040
这个能力还能直接用来搭建专业数据库，比如写Python脚本扫描法律、医疗合同，提取机构名和金额，自动生成Excel

104
00:11:57,350 --> 00:12:04,220
就算处理大文件，整个过程也只需要约10秒，比手动操作高效太多

105
00:12:04,570 --> 00:12:08,430
我刚给大家展示了经典论文《Attention Is All You Need》的文本处理效果

106
00:12:08,430 --> 00:12:16,170
相关代码我之后会分享~大家运行代码前，需要先配置Python环境

107
00:12:16,200 --> 00:12:21,810
对于零基础的同学，我会把配置过程讲得很详细，帮大家入门

108
00:12:22,520 --> 00:12:31,340
现在我来讲Python的基础环境配置，结合课前问卷，大家大多用Windows（我也是），所以主要用Windows演示

109
00:12:32,040 --> 00:12:36,800
Mac的操作流程基本一致，只有个别命令不一样（课程PDF会注明）

110
00:12:36,810 --> 00:12:42,210
如果跟不上，大家可以看课后整理的文档，这份文档也会发到群里

111
00:12:43,040 --> 00:12:56,700
第一步：从官网下载Python，推荐3.12或3.13版本，不要太新，避免和第三方库不兼容；也不要太旧，免得有系统漏洞

112
00:12:57,250 --> 00:13:04,300
Windows安装时，一定要勾选“将Python添加到系统路径”，避免后续手动配置环境变量

113
00:13:05,420 --> 00:13:18,610
第二步：Windows同学需要配置，Mac用户跳过！在系统搜索框搜PowerShell，选择“以管理员身份运行”，输入命令Get-ExecutionPolicy

114
00:13:18,840 --> 00:13:30,120
如果结果显示“Restricted”，说明电脑无法运行脚本，接着输入命令Set-ExecutionPolicy RemoteSigned，按Y确认，解锁脚本运行权限

115
00:13:30,820 --> 00:13:36,410
第三步：选一个编辑器，VS Code、PyCharm、Cursor都可以，这些工具都能正常使用

116
00:13:36,410 --> 00:13:38,260
大家按自己的需求选就行

117
00:13:38,790 --> 00:13:55,380
第四步：配置虚拟环境，这是关键步骤~建议不要所有项目共用一个环境，避免第三方库版本冲突，在项目文件夹打开终端，为每个项目建独立的虚拟环境

118
00:13:55,720 --> 00:14:05,840
Windows用指定命令创建并激活，Mac输入source venv/bin/activate即可激活后，命令行前面会出现(venv)的标识

119
00:14:06,250 --> 00:14:12,020
第五步：安装第三方库，用标准命令Pip install加上库名就行

120
00:14:12,670 --> 00:14:26,290
建议先装UV工具，命令是pip install uv，之后用uv pip install加库名安装，能大幅提高pandas、NLTK、SciPy这些库的下载速度

121
00:14:26,930 --> 00:14:50,570
环境配置好后，不用死记代码，也不用从头写，直接让AI协助生成Python脚本就行！简单的办公自动化需求，用自然语言把要求说清楚，比如让它写脚本读取PDF，提取所有数字、名词、术语、金额，最后保存到文件里

122
00:14:51,870 --> 00:14:59,640
如果做复杂项目，就学专业的提示词模板和技巧，让AI生成更贴合需求的代码

123
00:15:00,010 --> 00:15:03,550
大家直接把AI生成的代码复制到编辑器里，运行就可以

124
00:15:03,550 --> 00:15:12,810
Python不是一门需要死记硬背应付考试的课，而是实用工具，能解锁办公软件的高级功能，还能把各类工具串联起来

125
00:15:13,430 --> 00:15:23,210
掌握之后，还能实现本地文件和AI的联动，让AI理解本地的专业资料，进一步提升工作效率

126
00:15:23,920 --> 00:15:28,490
本次课程的所有操作步骤，都整理成了文档，发到群里了

127
00:15:28,490 --> 00:15:30,980
接下来我们进入问答环节

128
00:15:31,560 --> 00:15:36,120
大家可以打开麦克风提问，也可以共享屏幕，有问题直接问

129
00:15:36,130 --> 00:15:41,560
我也会展示演示幻灯片，方便大家跟着步骤，一步步进行Python的安装

130
00:15:42,320 --> 00:15:49,200
如果目前没有其他问题，本次课程就到这里~大家之后有相关问题，随时交流就好